{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seonhp/miniconda3/envs/ucc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from scipy.stats import norm\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BartForConditionalGeneration\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import ttest_ind\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\"'cause\": 'because',\n",
    " \"I'd\": 'I would',\n",
    " \"I'd've\": 'I would have',\n",
    " \"I'll\": 'I will',\n",
    " \"I'll've\": 'I will have',\n",
    " \"I'm\": 'I am',\n",
    " \"I've\": 'I have',\n",
    " \"ain't\": 'is not',\n",
    " \"aren't\": 'are not',\n",
    " \"can't\": 'cannot',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"didn't\": 'did not',\n",
    " \"doesn't\": 'does not',\n",
    " \"don't\": 'do not',\n",
    " \"hadn't\": 'had not',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he'd\": 'he would',\n",
    " \"he'll\": 'he will',\n",
    " \"he's\": 'he is',\n",
    " \"here's\": 'here is',\n",
    " \"how'd\": 'how did',\n",
    " \"how'd'y\": 'how do you',\n",
    " \"how'll\": 'how will',\n",
    " \"how's\": 'how is',\n",
    " \"i'd\": 'i would',\n",
    " \"i'd've\": 'i would have',\n",
    " \"i'll\": 'i will',\n",
    " \"i'll've\": 'i will have',\n",
    " \"i'm\": 'i am',\n",
    " \"i've\": 'i have',\n",
    " \"isn't\": 'is not',\n",
    " \"it'd\": 'it would',\n",
    " \"it'd've\": 'it would have',\n",
    " \"it'll\": 'it will',\n",
    " \"it'll've\": 'it will have',\n",
    " \"it's\": 'it is',\n",
    " \"let's\": 'let us',\n",
    " \"ma'am\": 'madam',\n",
    " \"mayn't\": 'may not',\n",
    " \"might've\": 'might have',\n",
    " \"mightn't\": 'might not',\n",
    " \"mightn't've\": 'might not have',\n",
    " \"must've\": 'must have',\n",
    " \"mustn't\": 'must not',\n",
    " \"mustn't've\": 'must not have',\n",
    " \"needn't\": 'need not',\n",
    " \"needn't've\": 'need not have',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"oughtn't've\": 'ought not have',\n",
    " \"sha'n't\": 'shall not',\n",
    " \"shan't\": 'shall not',\n",
    " \"shan't've\": 'shall not have',\n",
    " \"she'd\": 'she would',\n",
    " \"she'd've\": 'she would have',\n",
    " \"she'll\": 'she will',\n",
    " \"she'll've\": 'she will have',\n",
    " \"she's\": 'she is',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"shouldn't've\": 'should not have',\n",
    " \"so's\": 'so as',\n",
    " \"so've\": 'so have',\n",
    " \"that'd\": 'that would',\n",
    " \"that'd've\": 'that would have',\n",
    " \"that's\": 'that is',\n",
    " \"there'd\": 'there would',\n",
    " \"there'd've\": 'there would have',\n",
    " \"there's\": 'there is',\n",
    " \"they'd\": 'they would',\n",
    " \"they'd've\": 'they would have',\n",
    " \"they'll\": 'they will',\n",
    " \"they'll've\": 'they will have',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"this's\": 'this is',\n",
    " \"to've\": 'to have',\n",
    " \"wasn't\": 'was not',\n",
    " \"we'd\": 'we would',\n",
    " \"we'd've\": 'we would have',\n",
    " \"we'll\": 'we will',\n",
    " \"we'll've\": 'we will have',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"weren't\": 'were not',\n",
    " \"what'll\": 'what will',\n",
    " \"what'll've\": 'what will have',\n",
    " \"what're\": 'what are',\n",
    " \"what's\": 'what is',\n",
    " \"what've\": 'what have',\n",
    " \"when's\": 'when is',\n",
    " \"when've\": 'when have',\n",
    " \"where'd\": 'where did',\n",
    " \"where's\": 'where is',\n",
    " \"where've\": 'where have',\n",
    " \"who'll\": 'who will',\n",
    " \"who'll've\": 'who will have',\n",
    " \"who's\": 'who is',\n",
    " \"who've\": 'who have',\n",
    " \"why's\": 'why is',\n",
    " \"why've\": 'why have',\n",
    " \"will've\": 'will have',\n",
    " \"won't\": 'will not',\n",
    " \"won't've\": 'will not have',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"wouldn't've\": 'would not have',\n",
    " \"y'all\": 'you all',\n",
    " \"y'all'd\": 'you all would',\n",
    " \"y'all'd've\": 'you all would have',\n",
    " \"y'all're\": 'you all are',\n",
    " \"y'all've\": 'you all have',\n",
    " \"you'd\": 'you would',\n",
    " \"you'd've\": 'you would have',\n",
    " \"you'll\": 'you will',\n",
    " \"you'll've\": 'you will have',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics = glob('../origin_data//politics/*.txt')\n",
    "df_sport = glob('../origin_data//sport/*.txt')\n",
    "df_tech = glob('../origin_data//tech/*.txt')\n",
    "df_entertain = glob('../origin_data//entertainment/*.txt')\n",
    "df_business = glob('../origin_data//business/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df_normal, df_abnormal):\n",
    "\n",
    "    idx = np.random.permutation(len(df_normal))\n",
    "    # train_dataset, test_dataset_normal, test_dataset_abnormal, validation_dataset_normal = df_normal.iloc[idx[:994]], df_normal.iloc[idx[994:1175]], df_normal.iloc[idx[1175:1446]], df_normal.iloc[idx[1446:]]\n",
    "    train_dataset, test_dataset_normal, test_dataset_abnormal = df_normal.iloc[idx[:int(len(df_normal)*0.6)]], df_normal.iloc[idx[int(len(df_normal)*0.6):int(len(df_normal)*0.6)+int(len(df_normal)*0.2)]], df_normal.iloc[idx[int(len(df_normal)*0.6)+int(len(df_normal)*0.2):]]\n",
    "    \n",
    "    category_tr = [0] * len(train_dataset)\n",
    "    train_dataset['category'] = category_tr\n",
    "\n",
    "    category_te = [0] * len(test_dataset_normal)\n",
    "    test_dataset_normal['category'] = category_te\n",
    "\n",
    "    category_ab_te = [0] * len(test_dataset_abnormal)\n",
    "    test_dataset_abnormal['category'] = category_ab_te\n",
    "\n",
    "    ab_idx = np.random.permutation(len(df_abnormal))\n",
    "    ab_data = df_abnormal.iloc[ab_idx[:int(len(ab_idx)*0.2)]]\n",
    "\n",
    "    ab_category = [1] * len(ab_data)\n",
    "    ab_data['category'] = ab_category\n",
    "\n",
    "\n",
    "    test_dataset_abnormal_ = pd.concat([test_dataset_abnormal, ab_data], axis=0)\n",
    "    test_ab_idx = np.random.permutation(len(test_dataset_abnormal_))\n",
    "    test_dataset_abnormal_fi = test_dataset_abnormal_.iloc[test_ab_idx]\n",
    "    \n",
    "    test_dataset = pd.concat([test_dataset_normal, test_dataset_abnormal_fi], axis=0)\n",
    "    test_dataset = test_dataset.reset_index(drop=True)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # 문장을 벡터로 변환\n",
    "# def sentence_embedding(sentence):\n",
    "#     input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
    "#     outputs = model(input_ids)\n",
    "#     last_hidden_states = outputs.last_hidden_state\n",
    "#     sentence_embedding = torch.mean(last_hidden_states, dim=1).squeeze()\n",
    "#     return sentence_embedding.detach().numpy()\n",
    "\n",
    "# def make_vector(docs):\n",
    "#     train_docs_vector = []\n",
    "#     for sentences in tqdm(docs):\n",
    "#         sentence_vector = []\n",
    "#         for sentence in sentences.split('. '):\n",
    "#             sentence_vector.append(sentence_embedding(sentence))\n",
    "#         train_docs_vector.append(sentence_vector)\n",
    "\n",
    "#     docs_embedding = np.array([np.mean(train_docs_vector[idx], axis = 0) for idx in range(len(train_docs_vector))])\n",
    "#     return docs_embedding\n",
    "\n",
    "def sentence_embedding(sentence):\n",
    "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
    "    if len(input_ids[0])>512:\n",
    "        input_ids = input_ids[0][:512]\n",
    "        input_ids = input_ids.unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    sentence_embedding = torch.mean(last_hidden_states, dim=1).squeeze()\n",
    "    return sentence_embedding.detach().numpy()\n",
    "\n",
    "\n",
    "def make_vector(docs):\n",
    "    train_docs_vector = []\n",
    "    stop_words = set(stopwords.words('english'))  # 영어 stopwords를 사용할 경우\n",
    "\n",
    "    for sentences in tqdm(docs):\n",
    "        sentence_vector = []\n",
    "        for sentence in sentences.split('. '):\n",
    "            # stopwords를 제거한 후에 sentence_embedding 수행\n",
    "            sentence_clean = ' '.join([word for word in sentence.split() if word.lower() not in stop_words])\n",
    "            if sentence_clean.strip() != '':\n",
    "                sentence_vector.append(sentence_embedding(sentence_clean))\n",
    "            else:\n",
    "                sentence_vector.append(sentence_embedding(sentence))\n",
    "            \n",
    "        train_docs_vector.append(sentence_vector)\n",
    "\n",
    "    docs_embedding = np.array([np.mean(train_docs_vector[idx], axis=0) for idx in range(len(train_docs_vector))])\n",
    "    return docs_embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_politics+df_sport+df_tech+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1715/1715 [00:00<00:00, 9122.15it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 4138.64it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_business):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1028/1028 [05:33<00:00,  3.09it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 788/788 [04:10<00:00,  3.15it/s]\n",
      " 10%|█         | 1/10 [10:26<1:33:56, 626.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 390\n",
      "Delay: 59\n",
      "Group 1 proportion: 0.125\n",
      "Group 2 proportion: 0.312\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:34<00:00,  3.07it/s]\n",
      "100%|██████████| 788/788 [04:05<00:00,  3.21it/s]\n",
      " 20%|██        | 2/10 [20:51<1:23:24, 625.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 453\n",
      "Delay: 95\n",
      "Group 1 proportion: 0.087\n",
      "Group 2 proportion: 0.263\n",
      "t-statistic: -2.975\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:26<00:00,  3.15it/s]\n",
      "100%|██████████| 788/788 [04:13<00:00,  3.11it/s]\n",
      " 30%|███       | 3/10 [31:16<1:12:57, 625.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 469\n",
      "Delay: 103\n",
      "Group 1 proportion: 0.113\n",
      "Group 2 proportion: 0.300\n",
      "t-statistic: -2.994\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:30<00:00,  3.11it/s]\n",
      "100%|██████████| 788/788 [04:08<00:00,  3.17it/s]\n",
      " 40%|████      | 4/10 [41:39<1:02:27, 624.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 426\n",
      "Delay: 80\n",
      "Group 1 proportion: 0.113\n",
      "Group 2 proportion: 0.300\n",
      "t-statistic: -2.994\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:28<00:00,  3.13it/s]\n",
      "100%|██████████| 788/788 [04:10<00:00,  3.15it/s]\n",
      " 50%|█████     | 5/10 [52:02<51:58, 623.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 359\n",
      "Delay: 47\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:26<00:00,  3.15it/s]\n",
      "100%|██████████| 788/788 [04:09<00:00,  3.15it/s]\n",
      " 60%|██████    | 6/10 [1:02:22<41:31, 622.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 354\n",
      "Delay: 42\n",
      "Group 1 proportion: 0.087\n",
      "Group 2 proportion: 0.263\n",
      "t-statistic: -2.975\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:25<00:00,  3.16it/s]\n",
      "100%|██████████| 788/788 [04:08<00:00,  3.17it/s]\n",
      "100%|██████████| 1028/1028 [05:28<00:00,  3.13it/s]\n",
      "100%|██████████| 788/788 [04:08<00:00,  3.17it/s]\n",
      " 80%|████████  | 8/10 [1:23:01<20:42, 621.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 449\n",
      "Delay: 93\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:35<00:00,  3.07it/s]\n",
      "100%|██████████| 788/788 [04:00<00:00,  3.28it/s]\n",
      " 90%|█████████ | 9/10 [1:33:20<10:20, 620.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 437\n",
      "Delay: 86\n",
      "Group 1 proportion: 0.100\n",
      "Group 2 proportion: 0.275\n",
      "t-statistic: -2.891\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [05:25<00:00,  3.16it/s]\n",
      "100%|██████████| 788/788 [04:08<00:00,  3.16it/s]\n",
      "100%|██████████| 10/10 [1:43:38<00:00, 621.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 450\n",
      "Delay: 92\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.origin)\n",
    "    test_docs_embedding = make_vector(test_dataset.origin)\n",
    "\n",
    "\n",
    "    with open(f'business_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'business_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'business_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'business_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [626.3, 624.9, 625.1, 623.3, 622.4, 621.0, 617.4, 621.1, 618.9, 618.1]\n",
      "평균 621.85\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: [59, 95, 103, 80, 47, 42, 'none', 93, 86, 92]\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.44444444444444"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([59, 95, 103, 80, 47, 42, 93, 86, 92])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.8629441624365483, 0.8743654822335025, 0.8857868020304569, 0.8527918781725888, 0.8781725888324873, 0.8654822335025381, 0.8984771573604061, 0.9035532994923858, 0.8743654822335025, 0.8857868020304569]\n",
      "평균 0.8781725888324873\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.48125, 0.5103448275862069, 0.5454545454545454, 0.4551282051282051, 0.5238095238095238, 0.48717948717948717, 0.5932203389830508, 0.63, 0.5100671140939598, 0.5508474576271186]\n",
      "평균 0.5287301499862098\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.5877862595419847, 0.5991902834008097, 0.6153846153846153, 0.5503875968992248, 0.5789473684210527, 0.5891472868217054, 0.6363636363636364, 0.6237623762376239, 0.6055776892430279, 0.5909090909090909]\n",
      "평균 0.5977456203222771\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_sport+df_tech+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1808/1808 [00:00<00:00, 8892.21it/s]\n",
      "100%|██████████| 417/417 [00:00<00:00, 7069.08it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_politics):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_docs_vector = []\n",
    "# stop_words = set(stopwords.words('english'))  # 영어 stopwords를 사용할 경우\n",
    "\n",
    "# for sentences in tqdm(test_dataset.origin):\n",
    "#     sentence_vector = []\n",
    "#     for sentence in sentences.split('. '):\n",
    "#         # stopwords를 제거한 후에 sentence_embedding 수행\n",
    "        \n",
    "#         sentence_clean = ' '.join([word for word in sentence.split() if word.lower() not in stop_words])\n",
    "#         if sentence_clean.strip() != '':\n",
    "#             sentence_vector.append(sentence_embedding(sentence_clean))\n",
    "#         else:\n",
    "#             sentence_vector.append(sentence_embedding(sentence))\n",
    "\n",
    "            \n",
    "#         # sentence_vector.append(sentence_embedding(sentence))\n",
    "#     train_docs_vector.append(sentence_vector)\n",
    "\n",
    "# docs_embedding = np.array([np.mean(train_docs_vector[idx], axis=0) for idx in range(len(train_docs_vector))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1084/1084 [05:27<00:00,  3.31it/s]\n",
      "100%|██████████| 807/807 [03:59<00:00,  3.37it/s]\n",
      "100%|██████████| 1084/1084 [05:19<00:00,  3.39it/s]\n",
      "100%|██████████| 807/807 [04:25<00:00,  3.04it/s]\n",
      " 20%|██        | 2/10 [20:36<1:22:40, 620.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 983\n",
      "Delay: 348\n",
      "Group 1 proportion: 0.163\n",
      "Group 2 proportion: 0.362\n",
      "t-statistic: -2.934\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [05:32<00:00,  3.26it/s]\n",
      "100%|██████████| 807/807 [04:09<00:00,  3.24it/s]\n",
      "100%|██████████| 1084/1084 [05:40<00:00,  3.19it/s]\n",
      "100%|██████████| 807/807 [04:05<00:00,  3.28it/s]\n",
      " 40%|████      | 4/10 [41:25<1:02:18, 623.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 443\n",
      "Delay: 79\n",
      "Group 1 proportion: 0.150\n",
      "Group 2 proportion: 0.350\n",
      "t-statistic: -2.984\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [05:25<00:00,  3.33it/s]\n",
      "100%|██████████| 807/807 [04:08<00:00,  3.25it/s]\n",
      " 50%|█████     | 5/10 [51:39<51:38, 619.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 420\n",
      "Delay: 66\n",
      "Group 1 proportion: 0.212\n",
      "Group 2 proportion: 0.425\n",
      "t-statistic: -2.944\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [05:26<00:00,  3.32it/s]\n",
      "100%|██████████| 807/807 [04:22<00:00,  3.07it/s]\n",
      "100%|██████████| 1084/1084 [05:35<00:00,  3.23it/s]\n",
      "100%|██████████| 807/807 [04:08<00:00,  3.24it/s]\n",
      " 70%|███████   | 7/10 [1:12:32<31:09, 623.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 591\n",
      "Delay: 153\n",
      "Group 1 proportion: 0.150\n",
      "Group 2 proportion: 0.350\n",
      "t-statistic: -2.984\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [05:37<00:00,  3.22it/s]\n",
      "100%|██████████| 807/807 [03:59<00:00,  3.36it/s]\n",
      " 80%|████████  | 8/10 [1:22:49<20:42, 621.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 1060\n",
      "Delay: 377\n",
      "Group 1 proportion: 0.188\n",
      "Group 2 proportion: 0.388\n",
      "t-statistic: -2.848\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [05:30<00:00,  3.28it/s]\n",
      "100%|██████████| 807/807 [04:02<00:00,  3.32it/s]\n",
      "100%|██████████| 1084/1084 [05:25<00:00,  3.33it/s]\n",
      "100%|██████████| 807/807 [04:08<00:00,  3.25it/s]\n",
      "100%|██████████| 10/10 [1:43:16<00:00, 619.69s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.origin)\n",
    "    test_docs_embedding = make_vector(test_dataset.origin)\n",
    "\n",
    "\n",
    "    with open(f'politics{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'politics{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'politics{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'politics{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_params = {f1_s:[c,t]}\n",
    "                best_score = f1_s\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:3*i])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [608.5, 628.1, 623.4, 625.6, 613.8, 629.4, 623.7, 617.3, 614.2, 612.8]\n",
      "평균 619.68\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: ['none', 348, 'none', 79, 66, 'none', 153, 377, 'none', 'none']\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.6"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([348,  79, 66, 153, 377,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.828996282527881, 0.8042131350681536, 0.7434944237918215, 0.7695167286245354, 0.7397769516728625, 0.8228004956629492, 0.8017348203221809, 0.781908302354399, 0.7670384138785625, 0.8004956629491945]\n",
      "평균 0.785997521685254\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.302158273381295, 0.3271889400921659, 0.25396825396825395, 0.26046511627906976, 0.2529182879377432, 0.32558139534883723, 0.30456852791878175, 0.2731707317073171, 0.24880382775119617, 0.3160377358490566]\n",
      "평균 0.2864861090233716\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.3783783783783784, 0.47333333333333333, 0.382089552238806, 0.37583892617449666, 0.38235294117647056, 0.4392156862745098, 0.42857142857142855, 0.3888888888888889, 0.3561643835616438, 0.45423728813559316]\n",
      "평균 0.40590708067335496\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_sport+df_politics+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1824/1824 [00:00<00:00, 10094.66it/s]\n",
      "100%|██████████| 401/401 [00:00<00:00, 7839.75it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_tech):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1093/1093 [05:11<00:00,  3.51it/s]\n",
      "100%|██████████| 810/810 [04:06<00:00,  3.29it/s]\n",
      " 10%|█         | 1/10 [09:57<1:29:38, 597.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 401\n",
      "Delay: 58\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [05:06<00:00,  3.57it/s]\n",
      "100%|██████████| 810/810 [04:14<00:00,  3.18it/s]\n",
      " 20%|██        | 2/10 [19:58<1:19:55, 599.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 714\n",
      "Delay: 213\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [05:13<00:00,  3.48it/s]\n",
      "100%|██████████| 810/810 [04:04<00:00,  3.32it/s]\n",
      "100%|██████████| 1093/1093 [05:11<00:00,  3.51it/s]\n",
      "100%|██████████| 810/810 [04:05<00:00,  3.30it/s]\n",
      "100%|██████████| 1093/1093 [05:15<00:00,  3.46it/s]\n",
      "100%|██████████| 810/810 [04:00<00:00,  3.37it/s]\n",
      " 50%|█████     | 5/10 [49:50<49:48, 597.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 286\n",
      "Delay: 0\n",
      "Group 1 proportion: 0.150\n",
      "Group 2 proportion: 0.025\n",
      "t-statistic: 2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [05:16<00:00,  3.45it/s]\n",
      "100%|██████████| 810/810 [04:21<00:00,  3.09it/s]\n",
      " 60%|██████    | 6/10 [1:00:11<40:21, 605.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 296\n",
      "Delay: 2\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [05:27<00:00,  3.34it/s]\n",
      "100%|██████████| 810/810 [04:07<00:00,  3.27it/s]\n",
      " 70%|███████   | 7/10 [1:10:27<30:26, 608.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 394\n",
      "Delay: 52\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [05:19<00:00,  3.42it/s]\n",
      "100%|██████████| 810/810 [03:59<00:00,  3.38it/s]\n",
      "100%|██████████| 1093/1093 [05:16<00:00,  3.45it/s]\n",
      "100%|██████████| 810/810 [04:04<00:00,  3.31it/s]\n",
      "100%|██████████| 1093/1093 [05:12<00:00,  3.49it/s]\n",
      "100%|██████████| 810/810 [04:03<00:00,  3.32it/s]\n",
      "100%|██████████| 10/10 [1:40:22<00:00, 602.27s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.origin)\n",
    "    test_docs_embedding = make_vector(test_dataset.origin)\n",
    "\n",
    "\n",
    "    with open(f'tech_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'tech_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'tech_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'tech_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_params = {f1_s:[c,t]}\n",
    "                best_score = f1_s\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:3*i])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [597.7, 600.7, 598.9, 596.3, 597.0, 620.7, 616.2, 599.9, 600.3, 595.1]\n",
      "평균 602.28\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: [58, 213, 'none', 'none', 0, 2, 52, 'none', 'none', 'none']\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.0"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([58, 213, 0, 2, 52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.8419753086419753, 0.8827160493827161, 0.8962962962962963, 0.8716049382716049, 0.8839506172839506, 0.8950617283950617, 0.8691358024691358, 0.8481481481481481, 0.8617283950617284, 0.8629629629629629]\n",
      "평균 0.8713580246913579\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.35714285714285715, 0.43478260869565216, 0.47297297297297297, 0.4032258064516129, 0.4351851851851852, 0.4742268041237113, 0.4097222222222222, 0.37988826815642457, 0.3933333333333333, 0.3816793893129771]\n",
      "평균 0.4142159447596949\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.48387096774193544, 0.5128205128205128, 0.45454545454545453, 0.49019607843137253, 0.5, 0.519774011299435, 0.5267857142857143, 0.5250965250965252, 0.5130434782608696, 0.47393364928909953]\n",
      "평균 0.5000066391770919\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_politics+df_tech+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1714/1714 [00:00<00:00, 9157.38it/s]\n",
      "100%|██████████| 511/511 [00:00<00:00, 11105.82it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_sport):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1027/1027 [05:27<00:00,  3.14it/s]\n",
      "100%|██████████| 788/788 [04:04<00:00,  3.22it/s]\n",
      " 10%|█         | 1/10 [10:12<1:31:56, 612.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 317\n",
      "Delay: 27\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:24<00:00,  3.17it/s]\n",
      "100%|██████████| 788/788 [04:04<00:00,  3.22it/s]\n",
      " 20%|██        | 2/10 [20:21<1:21:20, 610.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 407\n",
      "Delay: 68\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:24<00:00,  3.16it/s]\n",
      "100%|██████████| 788/788 [04:06<00:00,  3.20it/s]\n",
      " 30%|███       | 3/10 [30:32<1:11:13, 610.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 343\n",
      "Delay: 35\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:23<00:00,  3.17it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 788/788 [04:16<00:00,  3.08it/s]\n",
      " 40%|████      | 4/10 [40:56<1:01:36, 616.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 462\n",
      "Delay: 99\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:46<00:00,  2.96it/s]\n",
      "100%|██████████| 788/788 [04:26<00:00,  2.96it/s]\n",
      " 50%|█████     | 5/10 [51:54<52:35, 631.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 460\n",
      "Delay: 98\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:52<00:00,  2.92it/s]\n",
      "100%|██████████| 788/788 [04:25<00:00,  2.96it/s]\n",
      " 60%|██████    | 6/10 [1:02:56<42:46, 641.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 465\n",
      "Delay: 94\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:43<00:00,  2.99it/s]\n",
      "100%|██████████| 788/788 [04:24<00:00,  2.98it/s]\n",
      " 70%|███████   | 7/10 [1:13:49<32:15, 645.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 816\n",
      "Delay: 276\n",
      "Group 1 proportion: 0.138\n",
      "Group 2 proportion: 0.325\n",
      "t-statistic: -2.867\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:44<00:00,  2.98it/s]\n",
      "100%|██████████| 788/788 [04:28<00:00,  2.93it/s]\n",
      " 80%|████████  | 8/10 [1:24:46<21:38, 649.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 677\n",
      "Delay: 205\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:47<00:00,  2.95it/s]\n",
      "100%|██████████| 788/788 [04:21<00:00,  3.01it/s]\n",
      " 90%|█████████ | 9/10 [1:35:37<10:49, 649.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 460\n",
      "Delay: 96\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [05:38<00:00,  3.03it/s]\n",
      "100%|██████████| 788/788 [04:17<00:00,  3.07it/s]\n",
      "100%|██████████| 10/10 [1:46:13<00:00, 637.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 447\n",
      "Delay: 92\n",
      "Group 1 proportion: 0.050\n",
      "Group 2 proportion: 0.200\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.origin)\n",
    "    test_docs_embedding = make_vector(test_dataset.origin)\n",
    "\n",
    "\n",
    "    with open(f'sport_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'sport_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'sport_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'sport_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_params = {f1_s:[c,t]}\n",
    "                best_score = f1_s\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:3*i])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [612.9, 608.1, 611.1, 624.6, 657.9, 662.2, 652.5, 657.3, 650.8, 636.2]\n",
      "평균 637.3599999999999\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: [27, 68, 35, 99, 98, 94, 276, 205, 96, 92]\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([27, 68, 35, 99, 98, 94, 276, 205, 96, 92])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.9365482233502538, 0.9111675126903553, 0.932741116751269, 0.916243654822335, 0.9416243654822335, 0.9378172588832487, 0.8934010152284264, 0.9251269035532995, 0.9238578680203046, 0.9175126903553299]\n",
      "평균 0.9236040609137056\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.7954545454545454, 0.6333333333333333, 0.7951807228915663, 0.6875, 0.8783783783783784, 0.8533333333333334, 0.5608108108108109, 0.8028169014084507, 0.7019230769230769, 0.6761904761904762]\n",
      "평균 0.7384921578723971\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.736842105263158, 0.6846846846846847, 0.7135135135135136, 0.6666666666666667, 0.7386363636363635, 0.7231638418079096, 0.6640000000000001, 0.6589595375722543, 0.7087378640776699, 0.6859903381642511]\n",
      "평균 0.6981194915386473\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_sport+df_tech+df_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1839/1839 [00:00<00:00, 8690.82it/s] \n",
      "100%|██████████| 386/386 [00:00<00:00, 7723.10it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_entertain):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1102/1102 [05:53<00:00,  3.12it/s]\n",
      "100%|██████████| 813/813 [04:29<00:00,  3.01it/s]\n",
      " 10%|█         | 1/10 [11:07<1:40:07, 667.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 443\n",
      "Delay: 74\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [05:49<00:00,  3.15it/s]\n",
      "100%|██████████| 813/813 [04:33<00:00,  2.98it/s]\n",
      " 20%|██        | 2/10 [22:13<1:28:51, 666.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 460\n",
      "Delay: 77\n",
      "Group 1 proportion: 0.037\n",
      "Group 2 proportion: 0.175\n",
      "t-statistic: -2.877\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [05:58<00:00,  3.07it/s]\n",
      "100%|██████████| 813/813 [04:13<00:00,  3.21it/s]\n",
      " 30%|███       | 3/10 [33:08<1:17:08, 661.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 483\n",
      "Delay: 95\n",
      "Group 1 proportion: 0.037\n",
      "Group 2 proportion: 0.175\n",
      "t-statistic: -2.877\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [05:56<00:00,  3.09it/s]\n",
      "100%|██████████| 813/813 [04:33<00:00,  2.97it/s]\n",
      " 40%|████      | 4/10 [44:22<1:06:37, 666.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 485\n",
      "Delay: 96\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:13<00:00,  2.95it/s]\n",
      "100%|██████████| 813/813 [04:31<00:00,  2.99it/s]\n",
      " 50%|█████     | 5/10 [55:52<56:14, 674.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 398\n",
      "Delay: 55\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:04<00:00,  3.02it/s]\n",
      "100%|██████████| 813/813 [04:26<00:00,  3.05it/s]\n",
      " 60%|██████    | 6/10 [1:07:08<45:01, 675.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 380\n",
      "Delay: 45\n",
      "Group 1 proportion: 0.037\n",
      "Group 2 proportion: 0.175\n",
      "t-statistic: -2.877\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:22<00:00,  2.88it/s]\n",
      "100%|██████████| 813/813 [04:42<00:00,  2.88it/s]\n",
      " 70%|███████   | 7/10 [1:19:00<34:22, 687.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 665\n",
      "Delay: 188\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:25<00:00,  2.86it/s]\n",
      "100%|██████████| 813/813 [04:50<00:00,  2.80it/s]\n",
      " 80%|████████  | 8/10 [1:31:02<23:16, 698.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 527\n",
      "Delay: 117\n",
      "Group 1 proportion: 0.050\n",
      "Group 2 proportion: 0.200\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:05<00:00,  3.02it/s]\n",
      "100%|██████████| 813/813 [04:15<00:00,  3.18it/s]\n",
      " 90%|█████████ | 9/10 [1:42:05<11:27, 687.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 816\n",
      "Delay: 261\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [06:05<00:00,  3.01it/s]\n",
      "100%|██████████| 813/813 [04:29<00:00,  3.02it/s]\n",
      "100%|██████████| 10/10 [1:53:25<00:00, 680.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 422\n",
      "Delay: 58\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.origin)\n",
    "    test_docs_embedding = make_vector(test_dataset.origin)\n",
    "\n",
    "\n",
    "    with open(f'entertain_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'entertain_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'entertain_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'entertain_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_params = {f1_s:[c,t]}\n",
    "                best_score = f1_s\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:3*i])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [667.5, 665.7, 655.1, 673.9, 690.1, 676.6, 711.8, 721.5, 662.9, 680.4]\n",
      "평균 680.55\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: [74, 77, 95, 96, 55, 45, 188, 117, 261, 58]\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.6"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([74, 77, 95, 96, 55, 45, 188, 117, 261, 58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.940959409594096, 0.9446494464944649, 0.933579335793358, 0.9348093480934809, 0.9618696186961869, 0.940959409594096, 0.9458794587945879, 0.9372693726937269, 0.9360393603936039, 0.9348093480934809]\n",
      "평균 0.9410824108241082\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.7101449275362319, 0.7666666666666667, 0.6533333333333333, 0.7142857142857143, 0.8709677419354839, 0.6933333333333334, 0.746268656716418, 0.6354166666666666, 0.6288659793814433, 0.65]\n",
      "평균 0.7069283019855291\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.6712328767123288, 0.6715328467153285, 0.6447368421052633, 0.6015037593984963, 0.7769784172661871, 0.6842105263157895, 0.6944444444444445, 0.7052023121387284, 0.7011494252873565, 0.6624203821656051]\n",
      "평균 0.6813411832549529\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x7fd0b1432680>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import pytextrank\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from icecream import ic\n",
    "from math import sqrt\n",
    "from operator import itemgetter\n",
    "nlp.add_pipe(\"textrank\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politics = glob('../origin_data//politics/*.txt')\n",
    "df_sport = glob('../origin_data//sport/*.txt')\n",
    "df_tech = glob('../origin_data//tech/*.txt')\n",
    "df_entertain = glob('../origin_data//entertainment/*.txt')\n",
    "df_business = glob('../origin_data//business/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_r(text):\n",
    "    doc = nlp(text)\n",
    "    sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
    "    # limit_phrases = 4\n",
    "    limit_phrases = len(sent_tokenize(text))//2\n",
    "\n",
    "    phrase_id = 0\n",
    "    unit_vector = []\n",
    "\n",
    "    for p in doc._.phrases:\n",
    "        # ic(phrase_id, p.text, p.rank)\n",
    "\n",
    "        unit_vector.append(p.rank)\n",
    "\n",
    "        for chunk in p.chunks:\n",
    "            # ic(chunk.start, chunk.end)\n",
    "\n",
    "            for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "                if chunk.start >= sent_start and chunk.end <= sent_end:\n",
    "                    # ic(sent_start, chunk.start, chunk.end, sent_end)\n",
    "                    sent_vector.add(phrase_id)\n",
    "                    break\n",
    "\n",
    "        phrase_id += 1\n",
    "\n",
    "        if phrase_id == limit_phrases:\n",
    "            break\n",
    "\n",
    "    sum_ranks = sum(unit_vector)\n",
    "\n",
    "    unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
    "\n",
    "    sent_rank = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent_start, sent_end, sent_vector in sent_bounds:\n",
    "        # ic(sent_vector)\n",
    "        sum_sq = 0.0\n",
    "        for phrase_id in range(len(unit_vector)):\n",
    "            # ic(phrase_id, unit_vector[phrase_id])\n",
    "\n",
    "            if phrase_id not in sent_vector:\n",
    "                sum_sq += unit_vector[phrase_id]**2.0\n",
    "\n",
    "        sent_rank[sent_id] = sqrt(sum_sq)\n",
    "        sent_id += 1\n",
    "\n",
    "    sorted(sent_rank.items(), key=itemgetter(1)) \n",
    "\n",
    "    # limit_sentences = len(sent_tokenize(text))//3\n",
    "    limit_sentences = len(sent_tokenize(text))//2\n",
    "\n",
    "    sent_text = {}\n",
    "    sent_id = 0\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        sent_text[sent_id] = sent.text\n",
    "        sent_id += 1\n",
    "\n",
    "    num_sent = 0\n",
    "    sum_text = []\n",
    "        \n",
    "    for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
    "        # ic(sent_id, sent_text[sent_id])\n",
    "        sum_text.append(sent_text[sent_id])\n",
    "        num_sent += 1\n",
    "\n",
    "        if num_sent == limit_sentences:\n",
    "            break\n",
    "    return sum_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_politics+df_sport+df_tech+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1715/1715 [00:00<00:00, 9226.34it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 10162.84it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_business):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1029/1029 [02:45<00:00,  6.22it/s]\n",
      "100%|██████████| 788/788 [02:11<00:00,  6.01it/s]\n",
      " 10%|█         | 1/10 [06:47<1:01:10, 407.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 351\n",
      "Delay: 41\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:50<00:00,  6.04it/s]\n",
      "100%|██████████| 788/788 [06:11<00:00,  2.12it/s]\n",
      " 20%|██        | 2/10 [19:09<1:20:33, 604.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 386\n",
      "Delay: 58\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:43<00:00,  6.28it/s]\n",
      "100%|██████████| 788/788 [02:00<00:00,  6.53it/s]\n",
      " 30%|███       | 3/10 [25:58<1:00:06, 515.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 1023\n",
      "Delay: 379\n",
      "Group 1 proportion: 0.087\n",
      "Group 2 proportion: 0.263\n",
      "t-statistic: -2.975\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:37<00:00,  6.53it/s]\n",
      "100%|██████████| 788/788 [02:15<00:00,  5.83it/s]\n",
      " 40%|████      | 4/10 [32:44<47:12, 472.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 420\n",
      "Delay: 77\n",
      "Group 1 proportion: 0.075\n",
      "Group 2 proportion: 0.237\n",
      "t-statistic: -2.886\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [06:09<00:00,  2.78it/s]\n",
      "100%|██████████| 788/788 [04:52<00:00,  2.70it/s]\n",
      " 50%|█████     | 5/10 [45:38<48:23, 580.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 590\n",
      "Delay: 162\n",
      "Group 1 proportion: 0.037\n",
      "Group 2 proportion: 0.175\n",
      "t-statistic: -2.877\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:45<00:00,  6.21it/s]\n",
      "100%|██████████| 788/788 [02:04<00:00,  6.32it/s]\n",
      " 60%|██████    | 6/10 [52:19<34:39, 519.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 1305\n",
      "Delay: 519\n",
      "Group 1 proportion: 0.087\n",
      "Group 2 proportion: 0.667\n",
      "t-statistic: -3.337\n",
      "p-value: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:55<00:00,  5.87it/s]\n",
      "100%|██████████| 788/788 [02:15<00:00,  5.81it/s]\n",
      " 70%|███████   | 7/10 [59:27<24:29, 489.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 640\n",
      "Delay: 185\n",
      "Group 1 proportion: 0.050\n",
      "Group 2 proportion: 0.200\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [03:11<00:00,  5.38it/s]\n",
      "100%|██████████| 788/788 [02:15<00:00,  5.80it/s]\n",
      "100%|██████████| 1029/1029 [02:59<00:00,  5.73it/s]\n",
      "100%|██████████| 788/788 [02:01<00:00,  6.50it/s]\n",
      " 90%|█████████ | 9/10 [1:13:43<07:35, 455.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 957\n",
      "Delay: 342\n",
      "Group 1 proportion: 0.062\n",
      "Group 2 proportion: 0.225\n",
      "t-statistic: -2.992\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1029/1029 [02:37<00:00,  6.55it/s]\n",
      "100%|██████████| 788/788 [01:58<00:00,  6.63it/s]\n",
      "100%|██████████| 10/10 [1:20:10<00:00, 481.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 447\n",
      "Delay: 91\n",
      "Group 1 proportion: 0.125\n",
      "Group 2 proportion: 0.312\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_sum = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        summ1 = text_r(train_dataset.origin.iloc[i])\n",
    "        train_sum.append(' '.join(summ1))\n",
    "    train_dataset['summary'] = train_sum\n",
    "\n",
    "    test_sum = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        summ2 = text_r(test_dataset.origin.iloc[i])\n",
    "        test_sum.append(' '.join(summ2))\n",
    "    test_dataset['summary'] = test_sum\n",
    "\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.summary)\n",
    "    test_docs_embedding = make_vector(test_dataset.summary)\n",
    "\n",
    "\n",
    "    with open(f'summary_business_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_business_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_business_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'summary_business_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [407.8, 741.5, 409.3, 406.1, 773.2, 401.8, 427.9, 443.5, 412.5, 386.3]\n",
      "평균 480.99000000000007\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: [41, 58, 379, 77, 162, 519, 185, 'none', 342, 91]\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.8401015228426396, 0.8642131979695431, 0.8908629441624365, 0.8604060913705583, 0.8908629441624365, 0.8984771573604061, 0.8895939086294417, 0.8807106598984772, 0.8984771573604061, 0.8489847715736041]\n",
      "평균 0.876269035532995\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.42857142857142855, 0.48031496062992124, 0.5769230769230769, 0.4722222222222222, 0.5833333333333334, 0.6145833333333334, 0.5714285714285714, 0.5307692307692308, 0.6195652173913043, 0.445859872611465]\n",
      "평균 0.5323571247213887\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.5333333333333333, 0.5327510917030568, 0.5825242718446602, 0.5528455284552845, 0.5656565656565657, 0.595959595959596, 0.5797101449275363, 0.5948275862068965, 0.5876288659793814, 0.5405405405405405]\n",
      "평균 0.5665777524606851\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_sport+df_tech+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1808/1808 [00:00<00:00, 9384.25it/s] \n",
      "100%|██████████| 417/417 [00:00<00:00, 7238.41it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_politics):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1084/1084 [02:36<00:00,  6.93it/s]\n",
      "100%|██████████| 806/806 [01:53<00:00,  7.13it/s]\n",
      "100%|██████████| 1084/1084 [02:34<00:00,  7.03it/s]\n",
      "100%|██████████| 806/806 [01:59<00:00,  6.76it/s]\n",
      "100%|██████████| 1084/1084 [02:35<00:00,  6.97it/s]\n",
      "100%|██████████| 806/806 [02:13<00:00,  6.04it/s]\n",
      "100%|██████████| 1084/1084 [02:44<00:00,  6.61it/s]\n",
      "100%|██████████| 806/806 [02:01<00:00,  6.62it/s]\n",
      " 40%|████      | 4/10 [25:48<39:00, 390.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 1307\n",
      "Delay: 507\n",
      "Group 1 proportion: 0.225\n",
      "Group 2 proportion: 0.714\n",
      "t-statistic: -2.918\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [02:33<00:00,  7.08it/s]\n",
      "100%|██████████| 806/806 [01:57<00:00,  6.86it/s]\n",
      "100%|██████████| 1084/1084 [02:44<00:00,  6.57it/s]\n",
      "100%|██████████| 806/806 [02:00<00:00,  6.72it/s]\n",
      "100%|██████████| 1084/1084 [02:31<00:00,  7.16it/s]\n",
      "100%|██████████| 806/806 [01:59<00:00,  6.74it/s]\n",
      "100%|██████████| 1084/1084 [02:26<00:00,  7.40it/s]\n",
      "100%|██████████| 806/806 [01:55<00:00,  6.99it/s]\n",
      " 80%|████████  | 8/10 [51:14<12:40, 380.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 537\n",
      "Delay: 117\n",
      "Group 1 proportion: 0.175\n",
      "Group 2 proportion: 0.375\n",
      "t-statistic: -2.888\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [02:30<00:00,  7.20it/s]\n",
      "100%|██████████| 806/806 [01:49<00:00,  7.35it/s]\n",
      " 90%|█████████ | 9/10 [57:17<06:14, 374.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 905\n",
      "Delay: 311\n",
      "Group 1 proportion: 0.225\n",
      "Group 2 proportion: 0.438\n",
      "t-statistic: -2.913\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1084/1084 [02:32<00:00,  7.10it/s]\n",
      "100%|██████████| 806/806 [01:55<00:00,  6.99it/s]\n",
      "100%|██████████| 10/10 [1:03:30<00:00, 381.06s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_sum = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        summ1 = text_r(train_dataset.origin.iloc[i])\n",
    "        train_sum.append(' '.join(summ1))\n",
    "    train_dataset['summary'] = train_sum\n",
    "\n",
    "    test_sum = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        summ2 = text_r(test_dataset.origin.iloc[i])\n",
    "        test_sum.append(' '.join(summ2))\n",
    "    test_dataset['summary'] = test_sum\n",
    "\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.summary)\n",
    "    test_docs_embedding = make_vector(test_dataset.summary)\n",
    "\n",
    "\n",
    "    with open(f'summary_politic_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_politic_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_politic_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'summary_politic_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [377.1, 379.0, 398.1, 394.3, 382.2, 398.6, 380.8, 364.2, 362.8, 373.5]\n",
      "평균 381.06000000000006\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: ['none', 'none', 'none', 507, 'none', 'none', 'none', 117, 311, 'none']\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.7208436724565757, 0.7704714640198511, 0.6600496277915633, 0.7965260545905707, 0.8039702233250621, 0.7642679900744417, 0.7481389578163772, 0.7741935483870968, 0.7617866004962779, 0.7555831265508685]\n",
      "평균 0.7555831265508683\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.2204724409448819, 0.2616822429906542, 0.19873817034700317, 0.2658959537572254, 0.2754491017964072, 0.24401913875598086, 0.2540983606557377, 0.25125628140703515, 0.2511415525114155, 0.2409090909090909]\n",
      "평균 0.24636623340754316\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.3323442136498516, 0.37710437710437705, 0.315, 0.359375, 0.36800000000000005, 0.3493150684931507, 0.3792048929663609, 0.35460992907801414, 0.36423841059602646, 0.3498349834983498]\n",
      "평균 0.3549026875386131\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_sport+df_politics+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1824/1824 [00:00<00:00, 4467.44it/s]\n",
      "100%|██████████| 401/401 [00:00<00:00, 4760.12it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_tech):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 1093/1093 [02:33<00:00,  7.13it/s]\n",
      "100%|██████████| 810/810 [01:52<00:00,  7.18it/s]\n",
      "100%|██████████| 1093/1093 [02:27<00:00,  7.42it/s]\n",
      "100%|██████████| 810/810 [01:59<00:00,  6.77it/s]\n",
      "100%|██████████| 1093/1093 [02:22<00:00,  7.69it/s]\n",
      "100%|██████████| 810/810 [01:54<00:00,  7.10it/s]\n",
      " 30%|███       | 3/10 [18:20<42:37, 365.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 1097\n",
      "Delay: 406\n",
      "Group 1 proportion: 0.188\n",
      "Group 2 proportion: 0.388\n",
      "t-statistic: -2.848\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [02:18<00:00,  7.91it/s]\n",
      "100%|██████████| 810/810 [01:58<00:00,  6.84it/s]\n",
      " 40%|████      | 4/10 [24:19<36:18, 363.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 603\n",
      "Delay: 159\n",
      "Group 1 proportion: 0.050\n",
      "Group 2 proportion: 0.200\n",
      "t-statistic: -2.927\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [02:24<00:00,  7.54it/s]\n",
      "100%|██████████| 810/810 [01:51<00:00,  7.24it/s]\n",
      " 50%|█████     | 5/10 [30:17<30:06, 361.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 633\n",
      "Delay: 174\n",
      "Group 1 proportion: 0.150\n",
      "Group 2 proportion: 0.350\n",
      "t-statistic: -2.984\n",
      "p-value: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1093/1093 [02:20<00:00,  7.78it/s]\n",
      "100%|██████████| 810/810 [01:58<00:00,  6.82it/s]\n",
      "100%|██████████| 1093/1093 [02:25<00:00,  7.51it/s]\n",
      "100%|██████████| 810/810 [01:52<00:00,  7.21it/s]\n",
      "100%|██████████| 1093/1093 [02:29<00:00,  7.30it/s]\n",
      "100%|██████████| 810/810 [01:47<00:00,  7.51it/s]\n",
      "100%|██████████| 1093/1093 [02:27<00:00,  7.42it/s]\n",
      "100%|██████████| 810/810 [01:51<00:00,  7.27it/s]\n",
      "100%|██████████| 1093/1093 [02:26<00:00,  7.47it/s]\n",
      "100%|██████████| 810/810 [01:51<00:00,  7.28it/s]\n",
      "100%|██████████| 10/10 [1:00:17<00:00, 361.73s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_sum = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        summ1 = text_r(train_dataset.origin.iloc[i])\n",
    "        train_sum.append(' '.join(summ1))\n",
    "    train_dataset['summary'] = train_sum\n",
    "\n",
    "    test_sum = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        summ2 = text_r(test_dataset.origin.iloc[i])\n",
    "        test_sum.append(' '.join(summ2))\n",
    "    test_dataset['summary'] = test_sum\n",
    "\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.summary)\n",
    "    test_docs_embedding = make_vector(test_dataset.summary)\n",
    "\n",
    "\n",
    "    with open(f'summary_tech_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_tech_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_tech_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'summary_tech_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 time: [368.9, 373.1, 358.2, 359.4, 358.1, 360.8, 359.1, 359.3, 361.1, 359.2]\n",
      "평균 361.71999999999997\n"
     ]
    }
   ],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 delay: ['none', 'none', 406, 159, 174, 'none', 'none', 'none', 'none', 'none']\n"
     ]
    }
   ],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 acc: [0.8802469135802469, 0.8641975308641975, 0.7901234567901234, 0.8950617283950617, 0.7913580246913581, 0.817283950617284, 0.8074074074074075, 0.7765432098765432, 0.8024691358024691, 0.8814814814814815]\n",
      "평균 0.8306172839506173\n"
     ]
    }
   ],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 precision: [0.38961038961038963, 0.3584905660377358, 0.27722772277227725, 0.463768115942029, 0.28502415458937197, 0.2976190476190476, 0.27647058823529413, 0.2672811059907834, 0.25903614457831325, 0.40476190476190477]\n",
      "평균 0.3279289740137147\n"
     ]
    }
   ],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각10번 f1: [0.3821656050955414, 0.4086021505376344, 0.3971631205673759, 0.4295302013422819, 0.41114982578397213, 0.4032258064516129, 0.376, 0.39057239057239057, 0.3495934959349593, 0.41463414634146345]\n",
      "평균 0.3962636742627232\n"
     ]
    }
   ],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_tech+df_politics+df_entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1714/1714 [00:00<00:00, 7470.08it/s]\n",
      "100%|██████████| 511/511 [00:00<00:00, 7184.31it/s]\n"
     ]
    }
   ],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_sport):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1027/1027 [02:26<00:00,  7.03it/s]\n",
      "100%|██████████| 788/788 [01:54<00:00,  6.89it/s]\n",
      " 10%|█         | 1/10 [06:04<54:36, 364.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 397\n",
      "Delay: 66\n",
      "Group 1 proportion: 0.037\n",
      "Group 2 proportion: 0.175\n",
      "t-statistic: -2.877\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [02:30<00:00,  6.84it/s]\n",
      "100%|██████████| 788/788 [01:50<00:00,  7.10it/s]\n",
      "100%|██████████| 1027/1027 [02:31<00:00,  6.80it/s]\n",
      "100%|██████████| 788/788 [01:50<00:00,  7.15it/s]\n",
      " 30%|███       | 3/10 [18:11<42:27, 363.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 409\n",
      "Delay: 72\n",
      "Group 1 proportion: 0.013\n",
      "Group 2 proportion: 0.125\n",
      "t-statistic: -2.866\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [02:28<00:00,  6.92it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 788/788 [01:53<00:00,  6.96it/s]\n",
      " 40%|████      | 4/10 [24:16<36:25, 364.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 482\n",
      "Delay: 109\n",
      "Group 1 proportion: 0.025\n",
      "Group 2 proportion: 0.150\n",
      "t-statistic: -2.851\n",
      "p-value: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [02:28<00:00,  6.90it/s]\n",
      "100%|██████████| 788/788 [01:58<00:00,  6.65it/s]\n",
      " 50%|█████     | 5/10 [30:31<30:40, 368.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째인지: 341\n",
      "Delay: 35\n",
      "Group 1 proportion: 0.000\n",
      "Group 2 proportion: 0.100\n",
      "t-statistic: -2.963\n",
      "p-value: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_sum = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        summ1 = text_r(train_dataset.origin.iloc[i])\n",
    "        train_sum.append(' '.join(summ1))\n",
    "    train_dataset['summary'] = train_sum\n",
    "\n",
    "    test_sum = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        summ2 = text_r(test_dataset.origin.iloc[i])\n",
    "        test_sum.append(' '.join(summ2))\n",
    "    test_dataset['summary'] = test_sum\n",
    "\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.summary)\n",
    "    test_docs_embedding = make_vector(test_dataset.summary)\n",
    "\n",
    "\n",
    "    with open(f'summary_sport_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_sport_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_sport_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'summary_sport_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = df_business+df_tech+df_politics+df_sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = []\n",
    "\n",
    "for lst in tqdm(normal_dataset):\n",
    "    file = open(lst, 'r')\n",
    "    data = file.read()\n",
    "    data = data.lower()\n",
    "    data = data.strip()\n",
    "    data = re.compile('<.*?>').sub('', data)\n",
    "    data = re.sub('\\s+', ' ', data)  \n",
    "    data = ' '.join([contractions[t] if t in contractions else t for t in data.split(\" \")]) # 약어 정규화\n",
    "    data = re.sub(r\"'s\\b\",\"\",data) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data = data.replace('\\n\\n', '\\n')\n",
    "    data = data.replace('\\n', '. ')\n",
    "    data = data.replace('..', '.')\n",
    "\n",
    "    txt.append(data)\n",
    "\n",
    "txt_2 = []\n",
    "\n",
    "for abnormal in tqdm(df_entertain):\n",
    "    file = open(abnormal, 'r')\n",
    "    data_ = file.read()\n",
    "    data_ = data_.lower()\n",
    "    data_ = data_.strip()\n",
    "    data_ = re.compile('<.*?>').sub('', data_)\n",
    "    data_ = re.sub('\\s+', ' ', data_)  \n",
    "    data_ = ' '.join([contractions[t] if t in contractions else t for t in data_.split(\" \")]) # 약어 정규화\n",
    "    data_ = re.sub(r\"'s\\b\",\"\",data_) # 소유격 제거. Ex) roland's -> roland\n",
    "    \n",
    "    data_ = data_.replace('\\n\\n', '\\n')\n",
    "    data_ = data_.replace('\\n', '. ')\n",
    "    data_ = data_.replace('..', '.')\n",
    "\n",
    "    txt_2.append(data_)\n",
    "\n",
    "df_normal = pd.DataFrame(txt, columns=['origin'])\n",
    "df_normal = df_normal.drop(df_normal.index[928])\n",
    "df_normal = df_normal.reset_index(drop=True)\n",
    "df_abnormal = pd.DataFrame(txt_2, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "clu = [5,10,15,20,25,30,35,40,45,50]\n",
    "threshold = np.arange(0,4.5,0.1)\n",
    "final_acc = []\n",
    "final_precision = []\n",
    "final_recall = []\n",
    "final_f1 = []\n",
    "final_delay = []\n",
    "epoch_time = []\n",
    "\n",
    "for n in tqdm(range(1, 11)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_dataset, test_dataset = make_dataset(df_normal, df_abnormal)\n",
    "    \n",
    "    train_sum = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        summ1 = text_r(train_dataset.origin.iloc[i])\n",
    "        train_sum.append(' '.join(summ1))\n",
    "    train_dataset['summary'] = train_sum\n",
    "\n",
    "    test_sum = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        summ2 = text_r(test_dataset.origin.iloc[i])\n",
    "        test_sum.append(' '.join(summ2))\n",
    "    test_dataset['summary'] = test_sum\n",
    "\n",
    "    \n",
    "    train_docs_embedding = make_vector(train_dataset.summary)\n",
    "    test_docs_embedding = make_vector(test_dataset.summary)\n",
    "\n",
    "\n",
    "    with open(f'summary_entertain_{n}_test_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_entertain_{n}_train_docs_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_docs_embedding, f)\n",
    "\n",
    "    with open(f'summary_entertain_{n}_test_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(test_dataset.category.values, f)\n",
    "\n",
    "    with open(f'summary_entertain_{n}_train_ans_embedding.pickle', 'wb') as f:\n",
    "        pickle.dump(train_dataset.category.values, f)\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    i = len(train_dataset)//3\n",
    "    \n",
    "    for c in clu:\n",
    "        \n",
    "        kmeans1 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "        kmeans2 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "        kmeans3 = KMeans(n_clusters=c, random_state=42)\n",
    "        kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "        # kmeans4 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "        # kmeans5 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "        # kmeans6 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "        # kmeans7 = KMeans(n_clusters=c, random_state=42)\n",
    "        # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "        distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "        distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "        # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "        for t in threshold:\n",
    "            predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "            predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "            predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "            # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "            # predictions6 = kmeans4.predict(test_docs_embedding)\n",
    "            # predictions7 = kmeans5.predict(test_docs_embedding)\n",
    "            \n",
    "            for idx in range(test_docs_embedding.shape[0]):\n",
    "                distances1[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans1.cluster_centers_[predictions1[idx]])\n",
    "                distances2[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans2.cluster_centers_[predictions2[idx]])\n",
    "                distances3[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans3.cluster_centers_[predictions3[idx]])\n",
    "                # distances4[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances5[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "                # distances6[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans4.cluster_centers_[predictions4[idx]])\n",
    "                # distances7[idx] = np.linalg.norm(test_docs_embedding[idx] - kmeans5.cluster_centers_[predictions5[idx]])\n",
    "            \n",
    "            predict_ensembel = (distances1>t) * 1 + (distances2>t) * 1 + (distances3>t) * 1 \n",
    "            # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "            \n",
    "            # +(distances6>t)* 1+(distances7>t)* 1\n",
    "            predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "            \n",
    "            acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "            f1_s = f1_score(test_dataset.category, predict)\n",
    "            # if acc_scores>best_score:\n",
    "            #     best_params = {acc_scores:[c,t]}\n",
    "            #     best_score = acc_scores\n",
    "            #     whole_window_ensemble = predict_ensembel\n",
    "            #     whole_window = predict\n",
    "            \n",
    "            if f1_s>best_score:\n",
    "                best_score = f1_s\n",
    "                best_params = {best_score:[c,t]}\n",
    "                whole_window_ensemble = predict_ensembel\n",
    "                whole_window = predict\n",
    "\n",
    "    \n",
    "    kmeans1 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans1.fit(train_docs_embedding[:i])\n",
    "\n",
    "    kmeans2 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans2.fit(train_docs_embedding[i:2*i])\n",
    "\n",
    "    kmeans3 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    kmeans3.fit(train_docs_embedding[2*i:])\n",
    "\n",
    "    # kmeans4 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans4.fit(train_docs_embedding[3*i:4*i])\n",
    "\n",
    "    # kmeans5 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans5.fit(train_docs_embedding[4*i:])\n",
    "\n",
    "    # kmeans6 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans6.fit(train_docs_embedding[5*i:6*i])\n",
    "\n",
    "    # kmeans7 = KMeans(n_clusters=best_params[best_score][0], random_state=42)\n",
    "    # kmeans7.fit(train_docs_embedding[6*i:])\n",
    "\n",
    "    distances1 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances2 = np.zeros(test_docs_embedding.shape[0])\n",
    "    distances3 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances4 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances5 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances6 = np.zeros(test_docs_embedding.shape[0])\n",
    "    # distances7 = np.zeros(test_docs_embedding.shape[0])\n",
    "\n",
    "    predictions1 = kmeans1.predict(test_docs_embedding)\n",
    "    predictions2 = kmeans2.predict(test_docs_embedding)\n",
    "    predictions3 = kmeans3.predict(test_docs_embedding)\n",
    "    # predictions4 = kmeans4.predict(test_docs_embedding)\n",
    "    # predictions5 = kmeans5.predict(test_docs_embedding)\n",
    "    # predictions6 = kmeans6.predict(test_docs_embedding)\n",
    "    # predictions7 = kmeans7.predict(test_docs_embedding)\n",
    "\n",
    "    for i in range(test_docs_embedding.shape[0]):\n",
    "        distances1[i] = np.linalg.norm(test_docs_embedding[i] - kmeans1.cluster_centers_[predictions1[i]])\n",
    "        distances2[i] = np.linalg.norm(test_docs_embedding[i] - kmeans2.cluster_centers_[predictions2[i]])\n",
    "        distances3[i] = np.linalg.norm(test_docs_embedding[i] - kmeans3.cluster_centers_[predictions3[i]])\n",
    "        # distances4[i] = np.linalg.norm(test_docs_embedding[i] - kmeans4.cluster_centers_[predictions4[i]])\n",
    "        # distances5[i] = np.linalg.norm(test_docs_embedding[i] - kmeans5.cluster_centers_[predictions5[i]])\n",
    "        # distances6[i] = np.linalg.norm(test_docs_embedding[i] - kmeans6.cluster_centers_[predictions6[i]])\n",
    "        # distances7[i] = np.linalg.norm(test_docs_embedding[i] - kmeans7.cluster_centers_[predictions7[i]])\n",
    "\n",
    "    predict_ensembel = (distances1>best_params[best_score][1]) * 1 + (distances2>best_params[best_score][1]) * 1 + (distances3>best_params[best_score][1]) * 1 \n",
    "    # + (distances4>t)* 1 +(distances5>t)* 1\n",
    "    # +(distances6>t)* 1+(distances7>t)* 1\n",
    "    predict = np.where(predict_ensembel>=2, 1, 0)\n",
    "\n",
    "    test_acc_scores = accuracy_score(test_dataset.category, predict)\n",
    "    test_pre_scores = precision_score(test_dataset.category, predict)\n",
    "    test_rec_scores = recall_score(test_dataset.category, predict)\n",
    "    test_f1_scores = f1_score(test_dataset.category, predict)\n",
    "    final_acc.append(test_acc_scores)\n",
    "    final_precision.append(test_pre_scores)\n",
    "    final_recall.append(test_rec_scores)\n",
    "    final_f1.append(test_f1_scores)\n",
    "\n",
    "    window_size = 80\n",
    "    ref_window = predict[:window_size]\n",
    "    ref_ratio = np.count_nonzero(ref_window) / len(ref_window)\n",
    "\n",
    "    first_ab_idx = test_dataset[test_dataset.category==1].index[0]-window_size\n",
    "    for delay in range(len(predict) - first_ab_idx):\n",
    "        compare_window = predict[first_ab_idx:first_ab_idx+window_size]\n",
    "        compare_ratio = np.count_nonzero(compare_window) / len(compare_window)\n",
    "        first_ab_idx+=1\n",
    "        t, p = ttest_ind(ref_window, compare_window)\n",
    "        if p<=0.005:\n",
    "            print('몇 번째인지:', delay+first_ab_idx)\n",
    "            print('Delay:', delay)\n",
    "            print(f\"Group 1 proportion: {ref_ratio:.3f}\")\n",
    "            print(f\"Group 2 proportion: {compare_ratio:.3f}\")\n",
    "            print(f\"t-statistic: {t:.3f}\")\n",
    "            print(f\"p-value: {p:.3f}\")\n",
    "            final_delay.append(delay)\n",
    "            break\n",
    "    if len(final_delay) != n:\n",
    "        final_delay.append('none')\n",
    "        \n",
    "    epoch_time.append(round(time.time() - start_time, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 time:', epoch_time)\n",
    "print('평균', np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 delay:', final_delay)\n",
    "# print('평균', np.mean(final_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 acc:', final_acc)\n",
    "print('평균', np.mean(final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 precision:', final_precision)\n",
    "print('평균', np.mean(final_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('각10번 f1:', final_f1)\n",
    "print('평균', np.mean(final_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
